1)How does this change the word cloud, and what are these changes telling you? Write down a short answer in your notes document.

Changing the settings for the stop words was interesting because you could see what words are most common, but this does not really give us any meaningful information. If the most common word all around is “the,” this does not give us much information about the most important themes in the text. However, when we changed the settings back to exclude the stop words, then we get a more meaningful sense of the words that are most representative of the texts. 

2)Why is relative frequency sometimes a more useful or accurate measure of a term’s importance than raw frequency? 

Relative frequency can be more helpful because we can see the most frequently-used words in a set of papers or data. For example, the word students may come up more frequently throughout all the texts, but this is obvious because of the nature of the articles we looked at. However, in terms of relative frequency, “mcas” was more prevalent, so this gives us the impression that this term could have been important for a few several types of documents and came up more frequently in that set. Thus, by examining this term specifically, we can gain a greater sense of other themes important to the news stories, and not just about students in general, but also specific events that happened that were important, such as the grievance letters. 
3) What is this document? And, more importantly, what have you learned about the term “mcas” in our corpus overall, and/or the utility or value of “significance” metrics like TF-IDF? 
We learned that the term “mcas” is more prevalent per ratio of articles, because its various ones it appears multiple times, whereas the words, “students” or “humanities” appears more often, but not per ratio of articles as much/frequently. This is valuable because it gives us a deeper sense as to what the news clips are about and not just broadly about students or the humanities in general. This grievance shows a different side of the texts we have and, if we were doing research on this, can show us a new way to approach the data we have and make new assumptions that have more meaning. The significance metrics kind of work like the stop words in that if we take these ratios into account, we get a deeper sense as to what we are looking at, and not just a broad view of what words are most popular, which might not tell us much, but looking at ratios per article makes more sense. 

4)Looking through this list of terms and their “Comparison” values, what observations can you make about terms that are more likely to occur in the humanities corpus vs. terms that are more likely to occur in the science corpus? How are these terms different?
The most common terms in the science corpus were similar in the pattern that we saw with the Humanities one in that they were general words that related to the field, such as “research,” or “science,” “said,” and “students.” I believe I included the stopwords here, so “said” came up as a frequently repeated word. The word, “students” was also used frequently, just as with the humanities corpus. This shows that although they are two different fields, they are connected by their dependency on students and research, which is the same with the humanities. The humanities corpus had common words like, “humanities,” “students,” and “research,” as well. This shows that you should be careful when analyzing the cirrus tool, in that it is not always the best way to determine field specific vocabulary, as it can be very general. 
 

5)  What tool(s) did you explore? What did this tool(s) help you to observe about this data and/or what did you learn about this data using this tool(s)? Alternatively, what did you hope to learn about this data using this tool and how (or why) did reality seem to fall short of that expectation?
I explored three different tools, the mandala, the bubble lines, and the scatterplot. I found the bubble lines and scatterplot to be easier to read than the mandala. The main problem with the mandala was that there were so many lines radiating to the various terms, that it was almost impossible to read anything. This turned out to be a jumbled mess that left me more confused, but I think for a smaller set of data, this could be more useful, as it is a great visual tool. On the other hand, the bubble lines were interesting in terms of how it clearly shows the frequency of a certain word showing up, as the bubble gets bigger. This is visually quite easy to see and get a sense of what words are most important in comparison to others that had smaller dots. It was striking to see the smaller and bigger bubbles side by side. Lastly, the scatterplot was also a useful tool, but it was also a little jumbled, just because there were so many words to work with. I would say that I would us the bubble lines again for a larger set of data and the others for a smaller set. Overall, I was hoping to get a strong visual sense of the prevalence of each word, such as the cirrus tool gives us, which I think is highly effective and useful. Concepts are a lot easier to understand visually, so I really wanted to find a tool that color-coded the words and showed some type of visual representation of the words getting larger or smaller. 

How this relates to the readings for week 5
Before taking this class, I never considered how software programs and data could help me in my research. However, especially after completing lab 4 and the readings for week 5, I see how Voyant, and other programming tools can help me tremendously. For example, using a tool like Voyant, I can narrow down a data set of articles I have or books to determine which could be most helpful for the keywords I am looking for. Even though I specialize in literature that is not in English, Voyant is still helpful as it caters to multiple languages. Likewise, the article for this week by Jo Guldi relating to search words in 19th century literature is especially relevant to my work. I think it is important to take into context the words used for the time period and how this translates to certain narratives of racial or cultural identities that could have been excluded. As Guldi states, the word “tenant,” which today is a very universally understood word, did not have the same universality or clarity for the time. These are important aspects to consider when looking at including or excluding stop words or words in the cirrus tool, because there could be elements missing. 
Similarly, the two pieces from Data in the Digital Humanities, show the increasing connection between programming tools and the humanities. Specifically Arnold and Tilton claim that, “In this chapter, we argue that three areas of statistics—exploratory data analysis (EDA), data visualization, and statistical computing—are central to the digital humanities;” this proves to be true when we explore tools like voyant this week or really any of the tools we have used in the past few weeks, from pivot tables to regular expressions. These tools enhance our research and show how graphics and forms can prove to be their own kind of evidence (Tilton and Arnold). This visualization can be important when examining literature during a certain time to analyze cultural aspects. For example, one of my research area interests is in 19th century Latin American literature, and I focus on many Colombian texts. Some of them relate to themes of race and slavery, so it would be interesting to see those terms mapped out to show how authors were talking about this cultural phenomena, as some even denounced these terrible acts and called for change, which would be interesting to see visually in a word cloud or using the tables and graphs Voyant provides to visually show how many authors were talking about these issues and in what context. However, we must be careful when using these tools, as we saw in class last week, since using certain functions of a program can lead us to believe some words or phrases are more prevalent than others, which can prove to be problematic, such as the stop words in Voyant or the differe
